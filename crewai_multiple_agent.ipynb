{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a61ab9-30de-49f0-ac39-9ab6186f7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crewai\n",
    "import json\n",
    "import os\n",
    "from crewai import Agent\n",
    "from crewai_tools import SerperDevTool\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1b1f7b-6759-4235-afc2-facc894b39d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c190d470-ab75-4843-8aa7-ad99ac5013ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process, Agent, Task\n",
    "search_tool = SerperDevTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d8bd8f-7098-4287-b4ad-c5bd89c1fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your agents\n",
    "researcher = Agent(\n",
    "  role='Researcher',\n",
    "  goal='Conduct foundational research',\n",
    "  backstory='An experienced researcher with a passion for uncovering insights'\n",
    ")\n",
    "\n",
    "analyst = Agent(\n",
    "  role='Data Analyst',\n",
    "  goal='Analyze research findings',\n",
    "  backstory='A meticulous analyst with a knack for uncovering patterns'\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "  role='Writer',\n",
    "  goal='Draft the final report',\n",
    "  backstory='A skilled writer with a talent for crafting compelling narratives'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c03eaaa-41e1-450c-a5e5-08e10dd58261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tasks in sequence\n",
    "# Research task\n",
    "research_task = Task(\n",
    "  description=(\n",
    "        \"\"\"\n",
    "        Interpret the question, marked by [QUESTION], and generate mutually exclusive questions. This means that one of\n",
    "        the questions must be true and the other answer must necessarily be false.\n",
    "        \n",
    "        Example 1:\n",
    "\n",
    "        Question - \"Will Instagram achieve 100,000 users by the end of 2025?\"\n",
    "        Output - '''\n",
    "        1 - Will Instagram achieve 100,000 or more users by the end of 2025?\n",
    "        2 - Will Instagram achieve less than 100,000 users by the end of 2025?\n",
    "\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        [QUESTION]\n",
    "        {{question}}\n",
    "        \"\"\"\n",
    "  ),\n",
    "  expected_output='''\n",
    "  A list containing 2 bullet points. Each bullet point should contain one question. \n",
    "  The two questions must be mutually exclusive.\n",
    "  ''',\n",
    "  #tools=[search_tool],\n",
    "    tools = [],\n",
    "  agent=researcher,\n",
    ")\n",
    "#analysis_task = Task(description='Analyze the data...', agent=analyst)\n",
    "#writing_task = Task(description='Compose the report...', agent=writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e4e7f91-bcf9-423c-9f76-8891739b260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the crew with a sequential process\n",
    "report_crew = Crew(\n",
    "  agents=[researcher],\n",
    "  #tasks=[research_task, analysis_task, writing_task],\n",
    "    tasks=[research_task],\n",
    "  process=Process.sequential\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05dd3975-b123-4369-a43b-e04613b7d65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I regret to inform that I can't provide the final answer without the original question to interpret. Please provide the original question so that I can generate the mutually exclusive questions.\n"
     ]
    }
   ],
   "source": [
    "# Starting the task execution process with enhanced feedback\n",
    "result = report_crew.kickoff(inputs={'question': 'Will Gnosis Pay reach 100k users by 2024?'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b5518bb-edcf-40ba-ae98-2ecdbed757d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Will the price of crypto increase in the next 2 months?\n",
      "2 - Will the price of crypto not increase in the next 2 months?\n"
     ]
    }
   ],
   "source": [
    "question = 'Will the price of crypto go up again in the next 2 months?'\n",
    "result = report_crew.kickoff(inputs={'question': question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b939c1f-a658-458e-b88c-87a27e76595b",
   "metadata": {},
   "source": [
    "# Other approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4152d0b-7a0e-424b-9c24-a8b97d97441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tasks in sequence\n",
    "# Research task\n",
    "research_prompt =         \"\"\"\n",
    "        You are asked about a SCENARIO, which can have multiple, mutually-exclusive outcomes.\n",
    "        You should break down the SCENARIO into a list of possible outcomes.\n",
    "        \n",
    "        Example 1:\n",
    "        - SCENARIO: Will Gnosis Pay reach 100,000 users by 2025?\n",
    "        - Answer: '''\n",
    "            - Gnosis Pay reaches less than 25,000 users by 2025\n",
    "            - Gnosis Pay reaches more than 25,000 users but less than 50,000 users by 2025\n",
    "            - Gnosis Pay reaches more than 50,000 users but less than 75,000 users by 2025\n",
    "            - Gnosis Pay reaches 100,000 users or more by 2025\n",
    "        '''\n",
    "\n",
    "        Example 2:\n",
    "        - SCENARIO: Will the price of Bitcoin go up again in the next 2 months?\n",
    "        - Answer: '''\n",
    "            - The price of crypto will go up in the next 2 months\n",
    "            - The price of crypto will not go up in the next 2 months\n",
    "        '''\n",
    "        \n",
    "        [SCENARIO]\n",
    "        {scenario}\n",
    "        \"\"\"\n",
    "expected_output = '''\n",
    "  A list containing multiple bullet points. Each bullet point should contain a possible outcome resulting from the\n",
    "  provided SCENARIO. The produced outcomes should be mutually exclusive, i.e. only one of them should be true whereas\n",
    "  the remaining ones should be false.\n",
    "  '''\n",
    "#analysis_task = Task(description='Analyze the data...', agent=analyst)\n",
    "#writing_task = Task(description='Compose the report...', agent=writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3420ddae-85be-4ba5-81b8-be8543ea26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_outcomes(question:str) -> None:\n",
    "    research_task = Task(\n",
    "  description=(research_prompt),\n",
    "  expected_output=expected_output,\n",
    "  #tools=[search_tool],\n",
    "    tools = [],\n",
    "  agent=researcher,\n",
    ")\n",
    "\n",
    "\n",
    "    report_crew = Crew(\n",
    "      agents=[researcher],\n",
    "        tasks=[research_task],\n",
    "      process=Process.sequential\n",
    "    )\n",
    "    result = report_crew.kickoff(inputs={'scenario': question})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2675c76-fba3-45eb-b29c-dd407fd98cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 18:13:54,197 - 140148875154688 - __init__.py-__init__:521 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Smart accounts fully replace EOAs in the EVM ecosystem within the next 3-5 years\n",
      "- Smart accounts partially replace EOAs in the EVM ecosystem within the next 3-5 years, but EOAs still maintain a significant presence\n",
      "- Smart accounts are adopted by a small minority within the EVM ecosystem, with the majority continuing to use EOAs within the next 3-5 years\n",
      "- Smart accounts are not adopted at all within the EVM ecosystem in the next 3-5 years, with EOAs maintaining full dominance.\n"
     ]
    }
   ],
   "source": [
    "question = 'Will smart accounts replace EOAs in the EVM ecosystem in the next 3-5 years?'\n",
    "print_outcomes(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "500a0dfe-233b-4a90-9183-e39e799a023d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 18:14:07,577 - 140148875154688 - __init__.py-__init__:521 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The temperature will be above 20C on May 24, 2024 in Berlin.\n",
      "- The temperature will be exactly 20C on May 24, 2024 in Berlin.\n",
      "- The temperature will be below 20C but above 10C on May 24, 2024 in Berlin.\n",
      "- The temperature will be below 10C but above 0C on May 24, 2024 in Berlin.\n",
      "- The temperature will be below 0C on May 24, 2024 in Berlin.\n"
     ]
    }
   ],
   "source": [
    "question = 'Will the temperature be above 20C on May 24, 2024 in Berlin?'\n",
    "print_outcomes(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e1cb34b-3913-4af3-a07b-623eef09c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 18:14:19,996 - 140148875154688 - __init__.py-__init__:521 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The exchange rate between Euro and Dollar will reach parity (1€ equals 1$) before 2027\n",
      "- The exchange rate between Euro and Dollar will not reach parity before 2027, but will come close (1€ equals between 1.01$ - 1.10$)\n",
      "- The exchange rate between Euro and Dollar will not come close to parity before 2027, with the Euro remaining stronger (1€ equals more than 1.10$)\n",
      "- The exchange rate between Euro and Dollar will not come close to parity before 2027, with the Dollar remaining stronger (1€ equals less than 0.90$)\n"
     ]
    }
   ],
   "source": [
    "question = 'Will there be a period in the currency market where 1€ equals 1$ before 2027?'\n",
    "print_outcomes(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b1602-f3ee-4f52-8e34-a7c034cebe4b",
   "metadata": {},
   "source": [
    "## Return probability of each affirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10307714-e445-4c09-a2a3-18884b46941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher = Agent(\n",
    "            role=\"Research Analyst\",\n",
    "            goal=\"Research and report on some future event, giving high quality and nuanced analysis\",\n",
    "            backstory=\"You are a senior research analyst who is adept at researching and reporting on future events.\",\n",
    "            verbose=True,\n",
    "            allow_delegation=False,\n",
    "            tools=[search_tool],\n",
    "        )\n",
    "predictor = Agent(\n",
    "            role=\"Professional Gambler\",\n",
    "            goal=\"Predict, based on some research you are presented with, whether or not a given event will occur\",\n",
    "            backstory=\"You are a professional gambler who is adept at predicting and betting on the outcomes of future events.\",\n",
    "            verbose=True,\n",
    "            allow_delegation=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce8c6c61-23e5-43bb-833a-4d2fb40a48dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 18:50:54,294 - 140148875154688 - __init__.py-__init__:521 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task1 = Task(\n",
    "            description=(\"\"\"\n",
    "                Research and report on the following sentence:\n",
    "                {sentence}\n",
    "                Search and scrape the web for information that will help you give a high quality, nuanced answer to the question.\n",
    "                \"\"\"\n",
    "            ),\n",
    "            tools=[search_tool],\n",
    "            agent=researcher,\n",
    "            expected_output=(\"\"\"\n",
    "            Return your answer in raw JSON format, with no special formatting such as newlines, as follows:\n",
    "                {{\"report\": <REPORT>}}\n",
    "                where <REPORT> is a free text field that contains a well though out justification \n",
    "                for the predicition based on the summary of your findings.\n",
    "            \"\"\"),\n",
    "        )\n",
    "task2 = Task(\n",
    "            description=(\"\"\"\n",
    "                    Your task is to determine the probability of a prediction market affirmation being answered 'Yes' or 'No'.\n",
    "Use the sentence provided in 'SENTENCE' and follow these guidelines:\n",
    "* Focus on the affirmation inside double quotes in 'SENTENCE'.\n",
    "* The question must have only 'Yes' or 'No' outcomes. If not, respond with \"Error\".\n",
    "* Use the tools provided to aid your estimation.\n",
    "* Evaluate recent information more heavily than older information.\n",
    "* Your response should include:\n",
    "    - \"decision\": The decision you made. Either `y` (for `Yes`) or `n` (for `No`).\n",
    "    - \"p_yes\": Probability that the sentence outcome will be `Yes`. Ranging from 0 (lowest probability) to 1 (maximum probability).\n",
    "    - \"p_no\": Probability that the sentence outcome will be `No`. Ranging from 0 (lowest probability) to 1 (maximum probability).\n",
    "    - \"confidence\": Indicating the confidence in the estimated probabilities you provided ranging from 0 (lowest confidence) to 1 (maximum confidence). \n",
    "    Confidence can be calculated based on the quality and quantity of data used for the estimation.\n",
    "    \n",
    "    Ensure p_yes + p_no equals 1.\n",
    "\n",
    "    SENTENCE: {sentence}\n",
    "              \"\"\"\n",
    "            ),\n",
    "        expected_output=\"\"\"\n",
    "    Your response should include:\n",
    "- \"decision\": The decision you made. Either `y` (for `Yes`) or `n` (for `No`).\n",
    "- \"p_yes\": Probability that the sentence outcome will be `Yes`. Ranging from 0 (lowest probability) to 1 (maximum probability).\n",
    "- \"p_no\": Probability that the sentence outcome will be `No`. Ranging from 0 (lowest probability) to 1 (maximum probability).\n",
    "- \"confidence\": Indicating the confidence in the estimated probabilities you provided ranging from 0 (lowest confidence) to \n",
    "1 (maximum confidence). Confidence can be calculated based on the quality and quantity of data used for the estimation.\n",
    "        \"\"\",\n",
    "            agent=predictor,\n",
    "        )\n",
    "crew = Crew(\n",
    "            agents=[researcher, predictor],\n",
    "            tasks=[task1, task2],\n",
    "            verbose=2,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7af9ade5-e35e-4239-9610-9f0a14ec8cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'\"report\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe temperature will be above 20C on May 24, 2024 in Berlin.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PMA/lib/python3.10/site-packages/crewai/crew.py:189\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Starts the crew to work on its assigned tasks.\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution_span \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_telemetry\u001b[38;5;241m.\u001b[39mcrew_execution_span(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpolate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n\u001b[1;32m    192\u001b[0m     agent\u001b[38;5;241m.\u001b[39mi18n \u001b[38;5;241m=\u001b[39m I18N(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguage)\n",
      "File \u001b[0;32m~/miniconda3/envs/PMA/lib/python3.10/site-packages/crewai/crew.py:279\u001b[0m, in \u001b[0;36mCrew._interpolate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_interpolate_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Interpolates the inputs in the tasks and agents.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     [task\u001b[38;5;241m.\u001b[39minterpolate_inputs(inputs) \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks]\n\u001b[1;32m    280\u001b[0m     [agent\u001b[38;5;241m.\u001b[39minterpolate_inputs(inputs) \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents]\n",
      "File \u001b[0;32m~/miniconda3/envs/PMA/lib/python3.10/site-packages/crewai/crew.py:279\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_interpolate_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Interpolates the inputs in the tasks and agents.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     [\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks]\n\u001b[1;32m    280\u001b[0m     [agent\u001b[38;5;241m.\u001b[39minterpolate_inputs(inputs) \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents]\n",
      "File \u001b[0;32m~/miniconda3/envs/PMA/lib/python3.10/site-packages/crewai/task.py:194\u001b[0m, in \u001b[0;36mTask.interpolate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: '\"report\"'"
     ]
    }
   ],
   "source": [
    "sentence = 'The temperature will be above 20C on May 24, 2024 in Berlin.'\n",
    "result = crew.kickoff(inputs={'sentence': sentence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15e8eb0b-e4cc-4760-ac05-31d05c699b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result {'decision': 'y', 'p_yes': 0.6, 'p_no': 0.4, 'confidence': 0.5}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#assert \"report\" in report\n",
    "loaded_result = json.loads(result)\n",
    "#assert \"prediction\" in result\n",
    "print (f'result {loaded_result}')\n",
    "print(True if loaded_result[\"decision\"] == \"y\" else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dedfcae4-2907-4f08-a17b-08c91a12f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = json.loads(task1.output.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd0a9365-cb7b-4761-8e74-3804043fcaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'report': \"Historical weather data indicates that the average high temperatures in Berlin during May range between 63°F (17.2°C) to 69°F (20.5°C). Therefore, it's possible that the temperature could exceed 20°C on May 24, 2024. However, without specific long-term forecasts for this date, a definitive prediction cannot be made. The actual temperature will depend on a variety of factors including global weather patterns and local conditions closer to the date.\"}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c4d44-486d-402b-b75d-dcd415b624ac",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "'''\n",
    "- Improve sentence generation - tell LLM to generate correct outcome first, then\n",
    "alternate outcomes afterwards.\n",
    "- Run script for each sentence\n",
    "- For each sentence, get highest probability (p_yes or p_no), multiply by confidence\n",
    "- Get sentence which makes the question be true and get likelihood from that\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d898db-780a-41ad-8a29-f0c4553daa3f",
   "metadata": {},
   "source": [
    "Example\n",
    "\n",
    "Q - Will the temperature be above 20C on May 24, 2024 in Berlin?\n",
    "\n",
    "Outcomes:\n",
    "1 - The temperature will be above 20C on May 24, 2024 in Berlin.\n",
    "2 - The temperature will be exactly 20C on May 24, 2024 in Berlin.\n",
    "3 - The temperature will be below 20C but above 10C on May 24, 2024 in Berlin.\n",
    "4 - The temperature will be below 10C but above 0C on May 24, 2024 in Berlin.\n",
    "5 - The temperature will be below 0C on May 24, 2024 in Berlin.\n",
    "\n",
    "We process the LLMs for each outcome, and we get the following\n",
    "\n",
    "1 - {confidence: 0.5, p_yes: 0.6, p_no: 0.4} -> p_yes selected (p_yes > p_no) -> 0.6 * 0.5 = 0.3 \n",
    "2 - {confidence: 0.9, p_yes: 0.9, p_no: 0.1} -> \n",
    "3 - {confidence: 0.4, p_yes: 0.8, p_no: 0.2}\n",
    "4 - {confidence: 0.3, p_yes: 0.7, p_no: 0.3}\n",
    "5 - {confidence: 0.4, p_yes: 0.7, p_no: 0.3}\n",
    "\n",
    "Note that outcome 1 is always a rephrase of the question. So we are only interUested in that outcome.\n",
    "The idea is, however, that we can \"normalize\" that outcome by the other probabilities and confidences.\n",
    "\n",
    "I have 2 ideas I would like to suggest:\n",
    "-> Get highest probability (max(p_yes,p_no)), normalize by the other probabilities, return that as probability that\n",
    "the question is true\n",
    "-> Use confidence as a \"weight\" for the probability before normalizing like above, i.e. \n",
    "\n",
    "$\\sum(w_i * p_i) = 1$\n",
    "\n",
    "and we return the normalized $(w_i * p_i)$ as the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ce677-95a3-4018-9ae1-7bad121098aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
